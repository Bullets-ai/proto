# ~80 seconds
# ~50 won
# Prevent bullet keyword duplication. Utilize. However, since ATS might check frequency, decided to remove that logic. This is for backup.
# Structured responsibility elements as skill + Goal.
from typing import List, Dict, Set, Any
import os
import uuid
import re
import csv
import time
import inspect
import math
from more_itertools import chunked 
import asyncio
from dateutil import parser
from dateutil.relativedelta import relativedelta
from datetime import datetime, date
from utils.score_utils import compute_resume_score, compute_total_experience_years
from collections import defaultdict
import pandas as pd
import numpy as np
import traceback
import spacy
from openai import OpenAI
from dotenv import load_dotenv
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup
import json
import ftfy
import ast
from jinja2 import Environment, FileSystemLoader
from collections import defaultdict
import tiktoken
import hashlib
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

# == Initial Setup ==

usage_records = []
load_dotenv('/Users/julee/Bullets/resume-ai-service/.env')

# 1) Model constants - Change one line to switch A/B versions
MODEL_EMBED = "text-embedding-3-small"   # Ultra-low cost embedding
MODEL_FAST  = "gpt-3.5-turbo"            # Mostly GPT calls
MODEL_SLOW  = "gpt-4-turbo"              # Summary/Rare fallback

# 2) Pricing table - Based on OpenAI (2025-06)
COST_TABLE = {
    "gpt-3.5-turbo": {"prompt": 0.001,  "completion": 0.002},
    "gpt-4-turbo":   {"prompt": 0.010,  "completion": 0.030},
    "text-embedding-3-small": {"prompt": 0.00002, "completion": 0.0},
}

# Map variant models like 4o to base model names
MODEL_ALIAS = {"gpt-4o": "gpt-4-turbo"}

API_KEY = os.getenv("OPENAI_API_KEY")
if not API_KEY:
    raise ValueError("OPENAI_API_KEY is missing in environment.")
client = OpenAI(api_key=API_KEY)
nlp = spacy.load(
    "en_core_web_sm",
    disable=["ner", "textcat", "lemmatizer", "tok2vec"])  # Keep only parser and noun_chunks


### 1) == Basic Utilities & Token/Cost Processing === ###

def calc_cost(model: str, prompt_t: int = 0, completion_t: int = 0) -> float:
    base = MODEL_ALIAS.get(model.split(":")[0], model.split(":")[0])
    if base not in COST_TABLE:
        return 0.0
    price = COST_TABLE[base]
    return round((prompt_t/1000)*price["prompt"] +
                 (completion_t/1000)*price["completion"], 6)

def log_usage(caller: str, model: str,
              prompt_t: int, completion_t: int) -> float:
    cost = calc_cost(model, prompt_t, completion_t)
    usage_records.append({
        "caller": caller,
        "model":  model,
        "prompt_tokens": prompt_t,
        "completion_tokens": completion_t,
        "total_tokens": prompt_t + completion_t,
        "cost_usd": cost,
    })
    return cost

_embed_cache = {}

def get_embed(text: str) -> np.ndarray:
    """Text to numpy vector, API called only once (cached)"""
    text = text.strip()
    if text in _embed_cache:
        #print(f"ðŸ§  [cache hit] {text[:60]}...")
        return _embed_cache[text]
    #print(f"ðŸ§  [embedding requested] {text[:60]}...")
    rsp = client.embeddings.create(model=MODEL_EMBED, input=text[:8192])
    vec = np.asarray(rsp.data[0].embedding, dtype=np.float32)

    #print(f"ðŸ”¢ Norm of embedding = {np.linalg.norm(vec):.4f}")
    # Aggregate token count & log cost
    # â‘¢ Get token count
    if hasattr(rsp, "usage") and rsp.usage is not None:
        prompt_t = rsp.usage.prompt_tokens
    else:                                        # (Temporary) Estimate with tiktoken if usage is unavailable
        enc = tiktoken.encoding_for_model(MODEL_EMBED)
        prompt_t = len(enc.encode(text))

    # â‘£ Log cost/tokens to usage_records
    log_usage("get_embed", MODEL_EMBED, prompt_t, 0)

    # â‘¤ Save to cache and return
    _embed_cache[text] = vec
    return vec

def prewarm_embeddings(
    bullets: list[str] = None,
    responsibilities: list[str] = None,
    keyword_meanings: list[str] = None
):
    """
    Pre-load all required texts into embedding cache before execution
    to prevent duplicate get_embed() calls.

    Args:
        bullets: Resume bullet list (merged["final_bullet"] etc)
        responsibilities: Responsibility meaning sentence list extracted from JD
        keyword_meanings: Keyword meaning sentence list generated by GPT
    """
    bullets = bullets or []
    responsibilities = responsibilities or []
    keyword_meanings = keyword_meanings or []

    # 1ï¸âƒ£ Create deduplicated full text set
    unique_texts = set()

    for b in bullets:
        if b and isinstance(b, str):
            unique_texts.add(b.strip())

    for r in responsibilities:
        if r and isinstance(r, str):
            unique_texts.add(r.strip())

    for m in keyword_meanings:
        if m and isinstance(m, str):
            unique_texts.add(m.strip())

    print(f"ðŸš€ Texts targeted for pre-embedding: {len(unique_texts)}")

    # 2ï¸âƒ£ Call get_embed only for uncached texts
    for text in unique_texts:
        _ = get_embed(text)



def cosine(a: np.ndarray, b: np.ndarray) -> float:
    norm_a = np.linalg.norm(a)
    norm_b = np.linalg.norm(b)
    if norm_a == 0 or norm_b == 0:
        print(f"âš ï¸ Zero vector detected: norm_a={norm_a}, norm_b={norm_b}")
        return 0.0
    """Simple cosine similarity"""
    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))

# === Simple Tokenizer ===

def simple_tokenize(text: str) -> set[str]:
    return set(re.findall(r"\w+", text.lower()))


# == Function to estimate tokens/cost just from prompt ==
def estimate_prompt_cost(prompt: str, model: str=MODEL_FAST, max_output: int=0):
    enc = tiktoken.encoding_for_model(model)
    tokens_in = len(enc.encode(prompt))
    rate = 0.001 if "3.5" in model else 0.01
    cost = (tokens_in + max_output) / 1000 * rate
    return tokens_in, round(cost,6)

def safe_parse_dict_json(content: str) -> dict:
    # 1) Trim whitespace
    text = content.strip()

    # 2) Remove leading/trailing markdown fences (``` or ```json)
    #    If it starts with ``` drop that line, if it ends with ``` drop that line.
    if text.startswith("```"):
        lines = text.splitlines()
        # drop first fence line
        lines = lines[1:]
        # if last line is a fence, drop it too
        if lines and lines[-1].strip().startswith("```"):
            lines = lines[:-1]
        text = "\n".join(lines).strip()

    # 3) Extract the first JSON object in the string
    m = re.search(r"\{.*\}", text, flags=re.DOTALL)
    if m:
        json_str = m.group(0)
    else:
        json_str = text

    # 4) Attempt parse
    try:
        parsed = json.loads(json_str)
        if isinstance(parsed, dict):
            return parsed
        else:
            print("âš ï¸ Parsed JSON is not a dict:", type(parsed))
            return {}
    except Exception as e:
        print(f"âŒ JSON Parsing Failed: {e}")
        print("â–¶ Cleaned text being parsed:", repr(json_str))
        return {}
    
def safe_parse_list_json(content: str) -> list:
    text = content.strip()

    # Remove code fences
    if text.startswith("```"):
        lines = text.splitlines()
        lines = lines[1:]
        if lines and lines[-1].strip().startswith("```"):
            lines = lines[:-1]
        text = "\n".join(lines).strip()

    # Extract JSON list block
    m = re.search(r"\[\s*\{.*?\}\s*\]", text, flags=re.DOTALL)
    if m:
        json_str = m.group(0)
    else:
        json_str = text

    try:
        parsed = json.loads(json_str)
        if isinstance(parsed, list):
            return parsed
        else:
            print("âš ï¸ Parsed JSON is not a list:", type(parsed))
            return []
    except Exception as e:
        print(f"âŒ JSON Parsing Failed (list): {e}")
        print("â–¶ Cleaned text being parsed:", repr(json_str))
        return []


def remove_datetime(obj):
    if isinstance(obj, dict):
        return {k: remove_datetime(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [remove_datetime(item) for item in obj]
    elif isinstance(obj, (datetime, date, pd.Timestamp)):
        return obj.isoformat()
    else:
        return obj


def fix_json_keys(text: str) -> str:
    return re.sub(r'(?m)^\s*([\w\s]+)\s*:', lambda m: f'"{m.group(1).strip()}":', text)

### 2) == Data Loading & Alias Mapping === ###

def load_alias_map(csv_path: str) -> dict[str, list[str]]:
    alias_map = {}
    alias_to_key = {}
    try:
        with open(csv_path, mode='r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            for row in reader:
                key = row.get("keyword", "").strip().lower()
                alias = row.get("alias", "").strip().lower()
                if not key or not alias:
                    continue
                prev = alias_to_key.get(alias)
                if prev and prev != key:
                    print(f"âš ï¸ Alias conflict: '{alias}' maps to both '{prev}' and '{key}'.")
                alias_to_key[alias] = key
                alias_map.setdefault(key, []).append(alias)
    except Exception as e:
        print(f"âš ï¸ Failed to load alias map from {csv_path}: {e}")
    return alias_map, alias_to_key



def extract_profile_used_keywords(profile_data: dict, all_keywords: set[str],
                                  alias_map: dict[str, list[str]],
                                  alias_to_key: dict[str, str],
                                  force_soft_skills: list[str] = None) -> set[str]:
    """
    Compare JD keywords and aliases based on text in profile.json â†’ Return matched used keywords
    """
    # Assume profile_data is already a safe dict
    profile_blob = json.dumps(profile_data, ensure_ascii=False).lower()

    used = set()

    for kw in all_keywords:
        norm_kw = kw.lower()

        # âœ… If JD keyword is an alias â†’ replace with actual keyword
        canonical_kw = alias_to_key.get(norm_kw, norm_kw)
        alias_list = alias_map.get(canonical_kw, [])

        # âœ… Consider used if original keyword or alias is included in resume
        if canonical_kw in profile_blob or any(alias in profile_blob for alias in alias_list):
            used.add(kw)

    if force_soft_skills:
        used.update(force_soft_skills)

    return used

def load_jd_text_from_file(path="/Users/julee/Bullets/resume-ai-service/data/jd_text.txt"):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        print("âŒ JD text file not found.")
        return ""
    
### 3) == JD Collection & Keyword Extraction === ###

def clean_html_tags(html):
    return BeautifulSoup(html, "html.parser").get_text(separator=" ", strip=True)


# === JD Collection ===
# === 1. Manual Input (Load from file) ===
def load_jd_from_file(manual_path: str = "data/jd_text.txt") -> str:
    try:
        with open(manual_path, "r", encoding="utf-8") as f:
            print("ðŸ“¥ JD text (manual input) loaded successfully")
            return f.read().strip()
    except Exception as e:
        print(f"âŒ Failed to load JD text file: {e}")
        return ""


# === 2. Auto-collect JD from LinkedIn ===
async def fetch_jd_from_linkedin(url: str) -> str:
    async with async_playwright() as pw:
        browser = await pw.chromium.launch(headless=True)
        page = await browser.new_page()
        await page.goto(url)
        await page.wait_for_timeout(3000)

        try:
            jd_element = page.locator("article.jobs-description__container")
            jd_text = await jd_element.inner_text()
            print("âœ… LinkedIn JD collected successfully")
        except Exception as e:
            print(f"âŒ JD collection failed: {e}")
            jd_text = ""

        await browser.close()
        return jd_text.strip()

# Temporary Chrome extension collection
async def fetch_jd_from_open_tab() -> dict:
    # Expected Playwright CDP connection or localStorage extraction
    # Actual extension might pass via window.postMessage or clipboard

    from playwright.async_api import async_playwright

    async with async_playwright() as pw:
        browser = await pw.chromium.connect_over_cdp("http://localhost:9222")
        context = browser.contexts[0]
        page = context.pages[0]  # First among opened tabs

        # ðŸ” Example: extract json from localStorage or page script
        try:
            jd_text = await page.locator("div#job-details").inner_text()
            job_title = await page.locator("h1").inner_text()
            company = await page.locator("a[data-test-app-aware-link]").inner_text()
            location = await page.locator("span.tvm__text").inner_text()
            post_url = page.url

            print("âœ… JD data collection successful")
            return {
                "job_title": job_title.strip(),
                "company": company.strip(),
                "location": location.strip(),
                "post_url": post_url,
                "jd_text": jd_text.strip()
            }

        except Exception as e:
            print("âŒ JD collection failed:", e)
            return {
                "job_title": "",
                "company": "",
                "location": "",
                "post_url": "",
                "jd_text": ""
            }


# === 3. Choose JD collection method based on user input ===
async def get_jd_info_interactive() -> dict:
    print("\nðŸ“Œ Select JD input method:")
    print("1: Manual input (Text file)")
    print("2: LinkedIn JD auto-collection (Opened Chrome tab)")

    mode = input("Input (1 or 2): ").strip()

    if mode == "1":
        jd_text = load_jd_from_file("data/jd_text.txt")
        job_title = input("Enter position title: ").strip() or "Data Analyst"
        company = input("Enter company name: ").strip() or "Unknown"
        location = input("Enter location: ").strip() or "N/A"
        post_url = input("Job URL (Optional): ").strip()
        return {
            "job_title": job_title,
            "company": company,
            "location": location,
            "post_url": post_url,
            "jd_text": jd_text.strip()
        }

    elif mode == "2":
        print("ðŸš€ Auto-collecting LinkedIn JD via extension.")
        print("ðŸ‘‰ Collecting data from the already opened Chrome tab.")
        # Extension â†’ collected from localStorage or fetch_jd_from_open_tab() etc.
        jd_data = await fetch_jd_from_open_tab()  # Collected via extension or Playwright
        return jd_data

    else:
        raise ValueError("âŒ Invalid input. Please select 1 or 2.")

# === 4. Extract JD keywords using GPT ===
def extract_keywords_from_jd_text(
    jd_text: str,
    job_title: str = "Data Analyst",
    alias_map: dict[str, list[str]] = None
):
    prompt = build_category_keywords_extraction_prompt(jd_text)
    response = gpt_call(prompt, model="gpt-3.5-turbo")
    print(f"[extract_keywords_from_jd_text] actual_cost=${response['cost_usd']}")

    parsed = parse_gpt_json_response(response["content"], debug_path="gpt_keyword_fallback_log.txt")
    jd_cost = response["cost_usd"]

    print("ðŸ“Š Extracted keywords by category:")
    for category, keywords in parsed.items():
        print(f"- {category}: {keywords}")

    # 1ï¸âƒ£ Basic extracted keywords
    tool = parsed.get("technologies and tools", [])
    hard = parsed.get("hard skills", [])
    soft = parsed.get("soft skills", [])
    knw  = parsed.get("knowledge", [])
    ind  = parsed.get("industry", [])
    edu  = parsed.get("education", [])
    exp  = parsed.get("experience", [])

    # 2ï¸âƒ£ Create category map
    category_map = {}
    for category, keywords in parsed.items():
        for kw in keywords:
            category_map[kw] = category

    return (
        job_title,
        tool,
        hard,
        knw,
        soft,
        ind,
        edu,
        exp,
        category_map,
        jd_cost
    )




def build_category_keywords_extraction_prompt(jd_text):
    prompt = None
    prompt =  f"""
You are an expert in HR and resume optimization for ATS (Applicant Tracking Systems).

Analyze the following job description and extract keywords that best match the following categories.

Only include keywords that:
- Are clearly relevant to the job responsibilities or qualifications
- Would improve a candidate's visibility in an ATS
- Are not vague or generic (âŒ avoid "integrity", "passion", etc.)
- Assign each keyword to only one category, even if it could fit multiple.

â— You MUST follow these rules:
- Each keyword must belong to ONLY ONE category.
- DO NOT return full phrases, only keyword terms.
- DO NOT include any sentence-like entries or subjective traits like "customer obsession".
- DO NOT duplicate the same keyword across categories.

ðŸ“‚ Extract up to:
- 10 ~ 15 keywords for **technologies and tools**
- 5 ~ 10 keywords for **hard Skills**
- 5 ~ 8 keywords for **soft Skills**
- 3 ~ 7 keywords for **knowledge**
- 2 ~ 5 keywords for **industry**
- 2 ~ 5 keywords for **education**
- 1 keywords for **experience**

ðŸ“‚ Categories:
1. **technologies and tools**: Software, hardware, or platforms used to complete tasks (e.g., Python, AWS, SQL, R, HTML, CSS, JIRA)
2. **hard skills**: Practical, learned abilities from training or experience (e.g., Data Analysis, Accounting)
3. **knowledge**: Theoretical or domain-specific understanding (e.g., GDPR, Economics)
4. **soft skills**: Interpersonal and behavioral skills (e.g., Communication, Leadership, self-motivated)
5. **industry**: The field or business domain (e.g., Fintech, Healthcare, Southeast Asia, Europe, IT Service)
6. **education**: Degrees, certifications, or fields of study (e.g., MBA, Bachelor's Degree, 5 years experience in Marketing, 3 years in Data Science)
7. **experience**: Extract only ONE integer that represents the **minimum required full-time professional experience** mentioned in the job description.

âš ï¸ You MUST follow these rules:
- Only extract a number if it refers to total or general **work experience** â€” not specific tools, certifications, or technologies.
- Only return a single integer (e.g., 4, 5, 7).
- Do NOT include any text, symbols, or ranges (âŒ "4+", "5 years", "7â€“8", etc).
- Only extract if a specific number of years is explicitly mentioned.
- If multiple values are mentioned, extract the **lowest** required value.
- If no years are mentioned, return an empty list.

âœ… Example:
- âœ… "5" â†’ correct
- âŒ "5 years" â†’ incorrect
- âŒ "4+" â†’ incorrect
- âŒ "7â€“8" â†’ incorrect

ðŸ“„ Job Description:
{jd_text}

---

â— Output Instructions:
- Respond using **only valid JSON**
- Do not include explanations, markdown, or commentary
- Return your response in this format:

{{
  "technologies and tools": ["..."],
  "hard skills": ["..."],
  "knowledge": ["..."],
  "soft skills": ["..."],
  "industry": ["..."],
  "education": ["..."],
  "experience" : ["..."]
}}
"""
    tokens, cost = estimate_prompt_cost(prompt, model=MODEL_FAST, max_output=200)
    print(f"[build_category_keywordsâ€¦] tokens={tokens}, est_cost=${cost}")
    return prompt


def parse_gpt_json_response(content, debug_path=None):
    """
    1) Attempt json.loads on entire content
    2) If failed, extract first JSON block using re.search for { ... }
    3) Fallback to line-by-line parsing
    """
    # 1) Attempt to parse entire string
    try:
        return json.loads(content)
    except json.JSONDecodeError:
        pass

    # 2) Extract JSON object block from body
    match = re.search(r"\{.*\}", content, re.S)
    if match:
        json_str = match.group(0)
        try:
            return json.loads(json_str)
        except json.JSONDecodeError:
            # fall through to line-by-line
            pass

    # 3) Line-by-line parsing (fallback)
    result_dict = {}
    for line in content.splitlines():
        line = line.strip()
        try:
            parsed = json.loads(line)
            if isinstance(parsed, dict):
                result_dict.update(parsed)
        except json.JSONDecodeError:
            continue

    # 4) If still empty, debug log
    if not result_dict and debug_path:
        with open(debug_path, "a", encoding="utf-8") as f:
            f.write("\n\nâŒ GPT response parsing failed:\n")
            f.write(content + "\n" + "-"*60)

    return result_dict




# === Interpret Keyword Meaning ===
def interpret_keyword(keyword, jd_text, category):
    parsed = {"semantic_structure": ""}

    # 1) Return empty for industry, education categories
    if category in {"industry", "education"}:
        return parsed, 0.0

    # 2) 'technologies and tools' â†’ Include JD
    if category == "technologies and tools":
        model = MODEL_FAST
        system_prompt = (
            "You are an HR and ATS optimization expert.\n"
            "Given a keyword of type TECHNOLOGY or TOOL and a job description, "
            "return a concise semantic phrase structured as:\n"
            "Action Verb + Object Noun/Noun Phrase + Context/Outcome.\n"
            "Use the job description to inform your phrasing.\n"
            "Return ONLY valid JSON: {\"semantic_structure\": \"...\"}.\n"
            "No additional explanation."
        )
        user_prompt = f"Keyword: {keyword}\n\nJob Description:\n{jd_text}"


    else:
        model = MODEL_FAST
        system_prompt = (
            "You are an HR and ATS optimization expert.\n"
            "Given a keyword related to a professional skill or domain knowledge,\n"
            "write a short semantic phrase structured as:\n"
            "Action Verb + Object Noun/Noun Phrase + Context/Outcome.\n"
            "Do NOT assume a job description.\n"
            "Return ONLY valid JSON: {\"semantic_structure\": \"...\"}.\n"
            "No explanation needed."
        )
        user_prompt = f"Keyword: {keyword}"

    
    # 4) Call GPT
    result = gpt_call(
        prompt=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        model=model,
        temperature=0.2
    )

     # 4) Parse response (with fallback)
    content = result["content"].strip()
    try:
        j = json.loads(content)
        if isinstance(j, dict) and "semantic_structure" in j:
            parsed = j
        elif isinstance(j, str):  # fallback: if it's just text
            parsed["semantic_structure"] = j.strip()
    except json.JSONDecodeError:
        parsed["semantic_structure"] = content  # fallback again

    return parsed, result["cost_usd"]


# === Deconstruct keyword meaning structure into Action/Obj/Context ===
def parse_keyword_structure(meaning_json):
    """
    Input: return value of interpret_keyword(), e.g. {"semantic_structure": "Extract data using SQL to generate insights."}
    Output: {"verb": "...", "object_np": "...", "context": "..."}
    """
    struct = meaning_json.get("semantic_structure", "")
    return extract_structured_components(struct)


def gpt_call(prompt, model=MODEL_SLOW, temperature=0.2, debug_log_dir="gpt_debug_logs"):
    
# 4-turbo
    caller = inspect.stack()[1].function

    messages = prompt if isinstance(prompt, list) else [{"role": "user", "content": prompt}]

    try:
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature
        )

        # Safe content extraction
        content = response.choices[0].message.content.strip() if response.choices else ""

        # Usage info
        usage = response.usage if hasattr(response, "usage") else None
        cost_usd = log_usage(caller, model,
                             usage.prompt_tokens if usage else 0,
                             usage.completion_tokens if usage else 0)
        
    except Exception as e:
        print(f"âŒ GPT call or response parsing failed: {e}")
        traceback.print_exc()
        content, usage, cost_usd = "", None, 0.0

    # Save response for debugging
    os.makedirs(debug_log_dir, exist_ok=True)
    with open(os.path.join(debug_log_dir,
              f"gpt_response_{uuid.uuid4().hex[:8]}.txt"), "w", encoding="utf-8") as f:
        f.write("=== Prompt ===\n")
        f.write("\n".join(m["content"] for m in messages))
        f.write("\n\n=== GPT Response ===\n")
        f.write(content)

    # Safe return structure
    

    return {
        "content": content,
        "tokens": {
            "prompt": usage.prompt_tokens if usage else 0,
            "completion": usage.completion_tokens if usage else 0,
            "total": usage.total_tokens if usage else 0
        },
        "total_tokens": usage.total_tokens if usage else 0,
        "cost_usd": cost_usd
    }


    #print(f"ðŸ“ GPT debug response saved â†’ {log_path}")



### 4) == JD Responsibility Summary & Core Keyword Extraction === ###

async def extract_responsibilities(jd_text: str) -> list[dict]:
    """
    Structurally extract responsibilities from JD text and return
    {"skills": [...], "goals": [...]} for each line.
    """
    prompt = f"""
You are an AI trained to extract business-relevant capabilities from job responsibilities.

For each line below, extract:
1. Key skills or tools mentioned (e.g., 'SQL', 'Power BI')
2. The implied business goal or problem the action is intended to solve (e.g., 'automate manual reporting', 'enable enterprise-level data analysis')

ðŸ›‘ Rules:
- Keep skill/tool and business goal as separate items
- Return format per line: {{"skills": [...], "goals": [...]}}

Responsibilities:
{jd_text}

âœ… Output:
[
  {{"skills": ["Power BI"], "goals": ["build dashboards"]}},
  ...
]
    """

    response = gpt_call(prompt=prompt, model=MODEL_FAST, temperature=0)
    content = response["content"].strip()

    try:
        parsed = json.loads(content)
        if isinstance(parsed, list) and all("skills" in x and "goals" in x for x in parsed):
            print("âœ… Structural responsibility extraction successful")
            return parsed
    except Exception as e:
        print("âŒ JSON parsing failed:", e)
        print("â–¶ Original response:", content[:300])

    return []


def fallback_parse_keywords(text: str) -> list[str]:
    """
    Process "1. [ ... ]" formatted response to extract full keyword list
    """

    matches = re.findall(r"\[[^\]]+\]", text)  # Extract all [ ... ] lists
    keywords = []

    for match in matches:
        try:
            parsed = json.loads(match)
            if isinstance(parsed, list):
                keywords.extend(parsed)
        except json.JSONDecodeError:
            continue

    return list(set(keywords))


def extract_keywords_from_structured_responsibilities(responsibility_struct: list[dict]) -> list[str]:
    keywords = set()
    for item in responsibility_struct:
        keywords.update(item.get("skills", []))
        keywords.update(item.get("goals", []))
    return list(keywords)



### 5) == Resume Matching (Fast Score + GPT-based keyword labeling) === ###

def build_bullet_text(bullet, tool, skill, goal, impact):
    bullet = "" if pd.isna(bullet) else str(bullet)
    tool = "" if pd.isna(tool) else str(tool)
    skill = "" if pd.isna(skill) else str(skill)
    goal = "" if pd.isna(goal) else str(goal)
    impact = "" if pd.isna(impact) else str(impact)

    scaffold = []
    if tool: scaffold.append(f"Tool: {tool}")
    if skill: scaffold.append(f"Skill: {skill}")
    if goal: scaffold.append(f"Goal: {goal}")
    if impact: scaffold.append(f"Impact: {impact}")
    
    meta = ", ".join(scaffold)
    return f"{bullet} ({meta})" if meta else bullet

# === Auto-labeling by category ===
def assign_label_by_score(row):
    category = str(row.get("Category", ""))
    fast_score = row.get("fast_score", 0)
    jaccard = row.get("jaccard", 0.0)
    bullet_text = str(row.get("bullet_text", "")).lower()
    keyword = str(row.get("keyword", "")).lower()

    reason = ""

    if len(keyword) <= 2:
        return 1.0, "short_keyword"

    if category == "hard skills":
        if fast_score >= 3 or jaccard >= 0.005:
            return 1.0, "fast_score >= 3 or jaccard >= 0.005"
        elif keyword in bullet_text:
            return 1.0, "keyword in bullet"
        else:
            return 0.0, "hard skill - no match"

    elif category == "technologies and tools":
        if fast_score >= 3 or jaccard >= 0.01:
            return 1.0, "fast_score >= 3 or jaccard >= 0.01"
        elif keyword in bullet_text:
            return 1.0, "keyword in bullet"
        else:
            return 0.0, "tool - no match"

    elif category == "industry":
        return (1.0, "keyword in bullet") if keyword in bullet_text else (0.0, "industry - no match")
    elif category == "experience":
        return 0.0, "skip experience - not bullet relevant"

    elif category in {"knowledge", "soft skills"}:
        return (1.0, "default pass")

# === Fast Score Calculation (Including reinforced conditions) ===
def compute_fast_score(row):
    kw      = str(row["keyword"]).lower()
    meaning = str(row["meaning"]).lower()
    bullet  = str(row["bullet_text"]).lower()
    tool    = str(row["Tool"]).lower()
    skill   = str(row.get("Skill", "")).lower()
    goal    = str(row["Goal"]).lower()
    impact  = str(row["Impact"]).lower()

    resume_text = f"{tool} {skill} {goal} {impact}"
    score = 0

    if kw in bullet or kw in resume_text:
        score += 1

    kw_tokens     = simple_tokenize(kw) | simple_tokenize(meaning)
    tool_tokens   = simple_tokenize(tool)
    skill_tokens  = simple_tokenize(skill)
    goal_tokens   = simple_tokenize(goal)
    impact_tokens = simple_tokenize(impact)
    bullet_tokens = simple_tokenize(bullet)

    score += 1 * len(kw_tokens & bullet_tokens)
    score += 3 * len(kw_tokens & skill_tokens)
    score += 3 * len(kw_tokens & tool_tokens)
    score += 1 * len(kw_tokens & goal_tokens)
    score += 1 * len(kw_tokens & impact_tokens)

    return score

def compute_semantic_score_from_responsibility(row, responsibility: str) -> int:
    """
    Calculate semantic similarity score between JD responsibility and bullet.
    Use only meaning without keyword.
    """
    meaning = responsibility.lower()
    bullet  = str(row["final_bullet"]).lower()
    tool    = str(row.get("Tool", "")).lower()

    kw_tokens     = simple_tokenize(meaning)
    bullet_tokens = simple_tokenize(bullet)
    tool_tokens   = simple_tokenize(tool)

    score = 0
    score += 1 * len(kw_tokens & bullet_tokens)
    score += 2 * len(kw_tokens & tool_tokens)

    return score



# === Calculate Jaccard Similarity ===
def compute_jaccard(row):
    kw_tokens     = simple_tokenize(f"{row['keyword']} {row['meaning']}")
    bullet_tokens = simple_tokenize(f"{row['Tool']} {row.get('Skill','')} {row['Goal']} {row['Impact']}")
    inter = kw_tokens & bullet_tokens
    union = kw_tokens | bullet_tokens
    return round(len(inter) / len(union), 3) if union else 0.0

def compute_duration(start_dt, end_dt):
    """
    start_dt, end_dt: datetime format â†’ returns "2 yrs 8 mos" format (integrated method)
    """
    try:
        if pd.isnull(start_dt) or pd.isnull(end_dt):
            return ""
        total_months = (end_dt.year - start_dt.year) * 12 + (end_dt.month - start_dt.month)
        years, months = divmod(total_months, 12)
        parts = []
        if years:
            parts.append(f"{years} yr{'s' if years > 1 else ''}")
        if months:
            parts.append(f"{months} mo{'s' if months > 1 else ''}")
        return " ".join(parts) if parts else "0 mo"
    except Exception:
        return ""




# === Extract Structured Components ===
def extract_structured_components(text):
    

    """
    Returns dict:
      {
        "verb": str, 
        "object_np": str, 
        "context": str
      }
    """
    doc = nlp(text)
    # 1) Action verb: Sentence root and VERB
    verb = ""
    for token in doc:
        if token.dep_ == "ROOT" and token.pos_ == "VERB":
            verb = token.lemma_
            break

    # 2) Object noun phrase: dobj, pobj of ROOT
    obj_chunks = []
    for chunk in doc.noun_chunks:
        if any(tok.dep_ in {"dobj","pobj"} for tok in chunk):
            obj_chunks.append(chunk.text)
    object_np = obj_chunks[0] if obj_chunks else ""

    # 3) Context/Outcome: clause after "led to", "resulting in" patterns
    context = ""
    patterns = ["led to", "resulting in", "resulted in", "enabled", "through"]
    for pat in patterns:
        idx = text.lower().find(pat)
        if idx != -1:
            context = text[idx:]
            break

    return {"verb": verb, "object_np": object_np, "context": context}

# â”€â”€â”€ â‘¡ "used / not-used" 1st Pass Embedding Filter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SIM_HI = 0.60      # â†‘ If above this value, almost certainly "used"
SIM_LO = 0.25      # â†“ If below this value, "not used"

def prefilter_used(bullet_text: str,
                   keyword_meaning: str) -> tuple[str, float]:
    """
    Quickly predict used/not-used/unsure via embedding cosine similarity.
      â€¢ bullet_text  : Resume single line
      â€¢ keyword_meaning : Meaning sentence generated by interpret_keyword() (verb obj ctx)

    Returns: ("used" | "not used" | "unsure", cosine score)
    """
    v_bullet  = get_embed(bullet_text)
    v_meaning = get_embed(keyword_meaning)
    sim = cosine(v_bullet, v_meaning)

    if sim >= SIM_HI:
        return "used", sim
    if sim <= SIM_LO:
        return "not used", sim
    return "unsure", sim

def process_resume_matching(jd_text, keywords, category_map, resume_csv_path):
    """
    jd_text: str â€” Collected original JD text
    keywords: List[str] â€” Keywords extracted by GPT
    category_map: Dict[str, str] â€” Keywordâ†’Category map
    resume_csv_path: str â€” Resume CSV path

    Returns: 
        - DataFrame containing only bullets with label=1
        - Total GPT cost
    """
    total_cost = 0.0

    # 1) Refine keywords
    keywords = [kw for kw in keywords if pd.notna(kw) and isinstance(kw, str) and kw.strip()]

    # 2) Load Resume CSV
    df = pd.read_csv(resume_csv_path)
    df['Start'] = pd.to_datetime(df['Start'], format='%Y.%m.%d', errors='coerce')
    df['End']   = pd.to_datetime(df['End'], format='%Y.%m.%d', errors='coerce')

    records = df.to_dict(orient='records')

    # 3) Cache bullet_text and structure analysis
    bullet_texts = [
        build_bullet_text(r["Bullet"], r["Tool"], r["Skill"], r["Goal"], r["Impact"])
        for r in records
    ]
    bullet_struct_map = {
        bt: extract_structured_components(bt)
        for bt in set(bullet_texts)
    }

    results = []

    for kw in keywords:
        category = category_map.get(kw, "").strip()

        # 3-1) Generate GPT meaning
        meaning_json, cost = interpret_keyword(kw, jd_text, category)
        total_cost += cost
        meaning = meaning_json.get("semantic_structure", "")
        kw_struct = parse_keyword_structure(meaning_json)

        # 3-2) Attempt mapping for each resume bullet
        for rec in records:
            bullet = rec.get("Bullet", "")
            tool   = rec.get("Tool", "")
            skill  = rec.get("Skill", "")
            goal   = rec.get("Goal", "")
            impact = rec.get("Impact", "")

            bullet_text = build_bullet_text(bullet, tool, skill, goal, impact)
            bullet_struct = bullet_struct_map[bullet_text]

            # 3-3) Calculate structure mapping
            verb_match = (kw_struct["verb"] and kw_struct["verb"] == bullet_struct["verb"])
            obj_match  = bool(simple_tokenize(kw_struct["object_np"]) & simple_tokenize(bullet_struct["object_np"]))
            ctx_match  = bool(simple_tokenize(kw_struct["context"]) & simple_tokenize(bullet_struct["context"]))

            result = {
                "keyword": kw,
                "meaning": meaning,
                "bullet_text": bullet_text,
                "Organization": rec.get("Organization", ""),
                "Sector": rec.get("Sector", ""),
                "Location": rec.get("Location", ""),
                "Start": rec.get("Start"),
                "End": rec.get("End"),
                "Duration": rec.get("Duration", ""),
                "Position": rec.get("Position", ""),
                "Job_title": rec.get("Job_title", ""),
                "Impact_Rank": rec.get("Impact_Rank", ""),
                "Bullet": bullet,
                "Tool": tool,
                "Skill": skill,
                "Goal": goal,
                "Impact": impact,
                "Category": category,
                "verb_match": verb_match,
                "object_match": obj_match,
                "context_match": ctx_match
            }

            # 3-4) Calculate score
            result["fast_score"] = compute_fast_score(result)
            result["jaccard"]    = compute_jaccard(result)

            # 3-5) Labeling
            label, reason = assign_label_by_score(result)
            result["label"] = label
            result["label_reason"] = reason

            results.append(result)

    # 4) Create DataFrame
    df_out = pd.DataFrame(results)

    if "fast_score" not in df_out.columns:
        print("â— [WARNING] fast_score missing â†’ creating column")
        df_out["fast_score"] = 0.0

    # 5) Filter bullets with label=1 only
    filtered_df = df_out[df_out["label"] == 1].reset_index(drop=True)

    print(f"âœ… process_resume_matching complete: total bullets={len(results)} / label=1 bullets={len(filtered_df)}")
    return filtered_df, total_cost

### 6) == Keyword Meaning Mapping & GPT Usage Determination === ###

def extract_bullet_tokens(row):
    """
    Input: DataFrame row (must include 'bullet_text', 'Tool')
    Output: dict { "verbs": [...], "nouns": [...] }
    """
    # 1) Lowercase regex tokenization for both original and Tool texts
    bt = str(row.get("bullet_text", "")).lower()
    tool_text = str(row.get("Tool", "")).lower()

    tokens = simple_tokenize(bt)
    tool_tokens = simple_tokenize(tool_text)

    all_tokens = tokens | tool_tokens

    # 2) Provide same token list for both verbs/nouns without distinction
    #    (Simplified for prompt usage if strict distinction isn't necessary)
    return {
        "verbs": list(all_tokens),
        "nouns": list(all_tokens)
    }

def build_token_match_prompt(bullet_tokens, keyword_meaning_map, tools_used, tool_text=None, bullet_text=None, ats_keywords=None):
    """
    bullet_tokens: dict â†’ {"verbs": [...], "nouns": [...]}
    keyword_meaning_map: dict â†’ {keyword: {"category": "...", "meaning": "..."}}
    """
    # Preprocess skill
    if isinstance(ats_keywords, list):
        ats_text = ", ".join(ats_keywords)
    else:
        ats_text = str(ats_keywords or "")
    ats_used = simple_tokenize(ats_text)
    ats_list = ats_text or "None"

    # Organize morphs/tokens
    bullet_verbs = ", ".join(bullet_tokens.get("verbs", []))
    bullet_nouns = ", ".join(bullet_tokens.get("nouns", []))
    tool_text = str(tool_text or "")  # Original string
    tools_used = simple_tokenize(tool_text) # token set â†’ for matching
    tool_list  = tool_text or "None" # to show to GPT
    
    # Construct keyword descriptions
    keyword_section = ""
    for kw, meta in keyword_meaning_map.items():
        combined_meaning = f"{kw.lower()}, {meta['meaning']}"
        keyword_section += f'\n- "{kw}" ({meta["category"]}): {meta["meaning"]}'

    # Construct GPT prompt
    prompt = f"""
You are an ATS resume evaluator.

Here is the extracted content from a resume bullet and its **ATS keyword list** (from the `Skill` column):
- Verbs: {bullet_verbs}
- Nouns and Tools: {bullet_nouns}
- Tools explicitly mentioned: {tool_list}
- ATS Keywords: {ats_keywords}

Below are keywords with their optimized meanings (expressed as short action phrases).

Rules:
- For keywords that represent **specific tools**, return "used" only if the tool is explicitly mentioned or can be confidently inferred.
- Do not infer tool usage from surrounding context. Tool keywords require explicit name match.
- Partial matches are acceptable for general skills or concepts, but not for tool names.
- For hard or soft skills, return "used" if the bullet includes actions, behaviors, or results that reflect the skill, even if the skill word is not directly stated.

Respond ONLY with valid JSON in this format:
{{
  "Keyword1": "used" | "not used",
  ...
}}

Keywords and meanings:
{keyword_section}
"""
    
    tokens, cost = estimate_prompt_cost(prompt, model=MODEL_FAST, max_output=100)
    return prompt

def get_rewrite_status(category_code: str,
                       used_keywords: list[str],
                       cleaned_bullet: str
                      ) -> tuple[str, list[str]]:
    """
    Determine whether to Delete, Keep, or Rewrite a bullet based on
    which used_keywords actually appear in its cleaned text.

    Args:
      category_code: e.g. "T", "H+S", "No"
      used_keywords: list of keywords flagged as 'used'
      cleaned_bullet: the bullet text without meta (Tool/Skill/etc) suffix

    Returns:
      status: "Delete" | "Keep" | "Rewrite"
      missing: list of used_keywords that were NOT found (empty if Keep/Delete)
    """
    text = cleaned_bullet.lower()

    # 1) If explicitly No or there are no used keywords, delete it
    if category_code == "No" or not used_keywords:
        return "Delete", []

    # 2) Check each keyword's presence
    missing = [kw for kw in used_keywords if kw.lower() not in text]

    # 3) If none missing â†’ keep
    if not missing:
        return "Keep", []

    # 4) Otherwise rewrite, and surface exactly which keywords to fold in
    return "Rewrite", missing



def run_keyword_labeling_loop(
    df: pd.DataFrame,
    profile_tools: Set[str],
    jd_kw_set: Set[str],
    alias_map: Dict[str, List[str]]
) -> List[Dict[str, Any]]:
    """
    Determines ATS keyword usage per bullet in Resume DataFrame(df) and returns result list.
    """
    results: List[Dict[str, Any]] = []
    df = df.copy()
    df["End_dt"] = pd.to_datetime(df["End"], errors="coerce")

    # âœ… Sort first: Recent bullets + High Impact first
    df = df.sort_values(by=["End", "Impact_Rank"], ascending=[False, True])

    # 1) Group by bullet_text + Organization
    for (bullet_text, org), group in df.groupby(["bullet_text", "Organization"]):
        first_row = group.iloc[0]
        tool_text = str(first_row.get("Tool", "")).lower()

        # â”€â”€ Remove meta: strip Tool/Skill/Goal/Impact (...) to extract pure text
        cleaned = re.sub(r"\s*\((?:Tool|Skill|Goal|Impact):.*\)$", "", bullet_text)
        lower_bullet = cleaned.lower()

        auto_labels: Dict[str, str] = {}
        gpt_candidates: Dict[str, Dict[str, str]] = {}

        # 2) Rule-based & prefilter labeling
        for _, row in group.iterrows():
            kw      = str(row["keyword"]).strip()
            cat     = row["Category"].lower()
            meaning = row["meaning"]

            # tools explicit match
            # tools explicit match
            if cat == "technologies and tools":
                kw_lower = kw.lower()
                tool_tokens = set(re.findall(r"\w+", tool_text))
                bullet_tokens = set(re.findall(r"\w+", lower_bullet))
                alias_tokens = set(alias.lower() for alias in alias_map.get(kw_lower, []))

                in_tool_text = kw_lower in tool_tokens or any(a in tool_tokens for a in alias_tokens)
                in_bullet = kw_lower in bullet_tokens or any(a in bullet_tokens for a in alias_tokens)

                auto_labels[kw] = "used" if in_tool_text or in_bullet else "not used"
                continue

                
            # industry substring
            if cat == "industry":
                auto_labels[kw] = "used" if kw.lower() in lower_bullet else "not used"
                continue

            # experience skip
            if cat == "experience":
                auto_labels[kw] = "not used"
                continue

            # embedding prefilter
            status, _ = prefilter_used(cleaned, meaning)
            if status in {"used", "not used"}:
                auto_labels[kw] = status
                continue

            # hard/soft/knowledge â†’ GPT candidates
            if cat in {"hard skills", "soft skills", "knowledge"}:
                gpt_candidates[kw] = {"category": row["Category"], "meaning": meaning}
                continue


        # 3) GPT-based labeling for uncertain cases
        parsed_gpt: Dict[str, str] = {}
        resp = {}
        if gpt_candidates:
            prompt = build_token_match_prompt(
                bullet_tokens=extract_bullet_tokens(first_row),
                keyword_meaning_map=gpt_candidates,
                tools_used=set(re.findall(r"\w+", tool_text)),
                tool_text=first_row.get("Tool", ""),
                bullet_text=cleaned,
                ats_keywords=list(gpt_candidates)
            )
            resp = gpt_call(prompt, model=MODEL_FAST, temperature=0)
            parsed = safe_parse_dict_json(resp["content"])

            # ambiguous check & fallback
            def is_ambiguous(lbls: Dict[str, str]) -> bool:
                return not lbls or any(v.lower() not in {"used","not used"} for v in lbls.values())

            if is_ambiguous(parsed):
                resp2 = gpt_call(prompt, model=MODEL_SLOW, temperature=0)
                parsed2 = safe_parse_dict_json(resp2["content"])
                if not is_ambiguous(parsed2):
                    parsed = parsed2

            parsed_gpt = {k: v for k, v in parsed.items() if v.lower() in {"used","not used"}}

        # 4) Combine labels
        final_labels = {**auto_labels, **parsed_gpt}
        used      = [kw for kw, lbl in final_labels.items() if lbl == "used"]
        not_used  = [kw for kw in final_labels if kw not in used]

        # 5) Determine rewrite status (use cleaned, not a DataFrame column)
        used_labels = {
            {"technologies and tools":"T","hard skills":"H","soft skills":"S","knowledge":"K","industry":"I"}[
                group[group["keyword"]==kw].iloc[0]["Category"].lower()
            ]
            for kw in used
            if group[group["keyword"]==kw].iloc[0]["Category"].lower() in
               {"technologies and tools","hard skills","soft skills","knowledge","industry"}
        }
        code = "+".join(sorted(used_labels)) if used_labels else "No"
        status, missing = get_rewrite_status(code, used, cleaned)


        # 6) Build detail scores
        keyword_score_total = 0
        detail: Dict[str, Dict[str, Any]] = {}

        if gpt_candidates:
            for kw, meta in gpt_candidates.items():
                score_row = {
                    "keyword":     kw,
                    "meaning":     meta["meaning"],
                    "bullet_text": cleaned,
                    "Tool":        first_row["Tool"],
                    "Skill":       first_row.get("Skill",""),
                    "Goal":        first_row.get("Goal",""),
                    "Impact":      first_row.get("Impact","")
                }
                fast_score = compute_fast_score(score_row)
                jaccard = compute_jaccard(score_row)

                if final_labels.get(kw, "not used") == "used":
                    keyword_score_total += fast_score

                detail[kw] = {
                    "Label":      final_labels.get(kw, "not used"),
                    "Category":   meta["category"],
                    "Meaning":    meta["meaning"],
                    "fast_score": fast_score,
                    "jaccard":    jaccard
                }

        to_rewrite = missing 

        results.append({
            "bullet_text":       bullet_text,
            "Organization":      first_row["Organization"],
            "Sector":            first_row.get("Sector",""),
            "Location":          first_row.get("Location",""),
            "Position":          first_row.get("Position",""),
            "Job_title":         first_row.get("Job_title",""),
            "Start":             first_row.get("Start"),
            "End":               first_row.get("End"),
            "Impact_Rank":       first_row.get("Impact_Rank"),
            "Matched_Category":  code,
            "Used_Keywords":     used,
            "Not_Used_Keywords": not_used,
            "Tool":              first_row.get("Tool",""),
            "Skill":             first_row.get("Skill",""),
            "Goal":              first_row.get("Goal",""),
            "Impact":            first_row.get("Impact",""),
            "Rewrite_Status":    status,
            "rewrite_keywords":  to_rewrite,
            "keyword_results":   detail,
            "tokens_used":       resp.get("total_tokens", 0),
            "cost_usd":          resp.get("cost_usd", 0),
            "keyword_score":     keyword_score_total
        })

    print(f"ðŸ“¦ run_keyword_labeling_loop complete: Total {len(results)} bullets generated")
    # added print inside loop

    return results


### 7) == Bullet Post-processing (ID/Sort/Rewrite) === ###

def ensure_list(x):
    """
    If rewrite_keywords is saved as string instead of list, convert to actual list via ast.literal_eval.
    """
    if isinstance(x, list):
        return x
    if isinstance(x, str):
        try:
            return ast.literal_eval(x)
        except (ValueError, SyntaxError):
            return []
    return []


def add_clean_and_id(results_df: pd.DataFrame) -> pd.DataFrame:
    """
    Remove (Tool:...) from bullet_text â†’ cleaned_bullet
    SHA1 hash cleaned_bullet â†’ bullet_id
    Force rewrite_keywords column to list
    """
    df = results_df.copy()
    pattern = re.compile(r"\s*\((?:Tool|Skill|Goal|Impact):.*\)$", re.DOTALL)

    # 1) Create clean_bullet by removing meta annotations
    df['cleaned_bullet'] = df['bullet_text'].astype(str).str.replace(pattern, '', regex=True)

    # 2) Create SHA1 hashed bullet_id
    df['bullet_id'] = df['cleaned_bullet'].apply(
        lambda s: hashlib.sha1(s.encode('utf-8')).hexdigest()
    )

    # 3) Force rewrite_keywords to list
    df['rewrite_keywords'] = df['rewrite_keywords'].apply(ensure_list)

    return df

def prepare_bullet_table(results_df: pd.DataFrame) -> pd.DataFrame:
    """
    1) Use 'cleaned_bullet' and 'bullet_id' generated by add_clean_and_id()
    2) Use cleaned_bullet as 'bullet' based on Keep/Rewrite status
    3) Columns: bullet, Organization, Sector, Location, Position, Job_title, Start, End, Impact_Rank, Tool, bullet_id
    4) Concat Keep cases first, then Rewrite cases
    5) Sort descending by End, ascending by Impact_Rank, then return
    """
    # results_df should already have 'cleaned_bullet' and 'bullet_id'
    # (Assuming add_clean_and_id() was called first in main())

    # Keep case
    keep_df = results_df[results_df['Rewrite_Status'] == 'Keep'].copy()
    keep_df['bullet'] = keep_df['cleaned_bullet']
    keep_sel = keep_df[[
        'bullet', 'Organization', 'Sector', 'Location',
        'Position','Job_title', 'Start', 'End', 'Impact_Rank', 'Tool', 'bullet_id'
    ]]

    # Rewrite case
    rewrite_df = results_df[results_df['Rewrite_Status'] == 'Rewrite'].copy()
    rewrite_df['bullet'] = rewrite_df['cleaned_bullet']
    rewrite_sel = rewrite_df[[
        'bullet', 'Organization', 'Sector', 'Location',
        'Position','Job_title', 'Start', 'End', 'Impact_Rank', 'Tool', 'bullet_id'
    ]]

    # Combine Keep first, Rewrite later, then sort
    bullet_table = pd.concat([keep_sel, rewrite_sel], ignore_index=True)

    bullet_table["Start_dt"] = pd.to_datetime(bullet_table["Start"], errors="coerce")
    bullet_table["End_dt"]   = pd.to_datetime(bullet_table["End"], errors="coerce")
    
    bullet_table["Duration"] = bullet_table.apply(
    lambda r: compute_duration(r["Start_dt"], r["End_dt"]), axis=1)

    bullet_table = bullet_table.sort_values(
        by=['End_dt', 'Impact_Rank'], ascending=[False, True]
    ).reset_index(drop=True)

    return bullet_table


def compute_company_score(df: pd.DataFrame, jd_keywords: set[str]) -> pd.DataFrame:
    def row_score(row):
        keyword_score = row.get("keyword_score", 0.0)
        used_kw = set(row.get("Used_Keywords", []))
        num_matched = len(used_kw & jd_keywords)
        cover_ratio = num_matched / max(1, len(jd_keywords))
        responsibility_score = row.get("responsibility_score", 0.0)

        # âœ… Reflect Impact_Rank (Reverse: 6 - Impact_Rank, with minimum limit)
        impact_rank = row.get("Impact_Rank", 6)
        try:
            rank_score = max(0, 6 - float(impact_rank))  # ex: Impact_Rank=1 â†’ rank_score=5
        except:
            rank_score = 0

        return (
            cover_ratio +
            0.05 * keyword_score +
            0.1 * responsibility_score +
            0.03 * rank_score  # â† âœ… Can adjust weights as desired
        )

    if "Used_Keywords" not in df.columns or "keyword_score" not in df.columns:
        df["keyword_score"] = 0.0
        df["Used_Keywords"] = [[] for _ in range(len(df))]

    df["num_keywords_matched"] = df["Used_Keywords"].apply(lambda used: len(set(used) & jd_keywords))
    df["cover_ratio"] = df["num_keywords_matched"] / max(1, len(jd_keywords))
    df["company_score"] = df.apply(row_score, axis=1)

    return df



def execute_rewrites(results_df: pd.DataFrame,
                     model: str = MODEL_FAST,
                     temperature: float = 0.2) -> pd.DataFrame:
    """
    Rewrites bullets using GPT with enforced keyword coverage, HR-style structure, and natural phrasing.
    """

    # ðŸ”§ Post-processing function
    def clean_output(text: str) -> str:
        text = text.strip()
        if text.startswith("- "):
            text = text[2:]
        if text.startswith(("\"", "'")) and text.endswith(("\"", "'")):
            text = text[1:-1]
        return text.strip()

    system_prompt_template = (
        "You are an expert resume writer. Your task is to rewrite the following resume bullet to improve clarity, flow, "
        "and keyword alignment, while keeping the user's tone and structure.\n\n"
        "Your most important rule:\n"
        "âž¡ï¸ You MUST incorporate all of the listed keywords below.\n"
        "Each keyword must appear exactly as written, and all keywords must be included.\n"
        "They must be used in a natural, fluent, and human sentenceâ€”not simply listed or stacked.\n"
        "Do not paraphrase, skip, or summarize them.\n\n"
        "---\n\n"
        "ã€Contextã€‘\n"
        "Original Bullet: {original_bullet}\n"
        "Goal: {goal}\n"
        "Impact: {impact}\n\n"
        "ã€Used Keywordsã€‘\n"
        "Below is a list of keywords that must be used exactly as written.\n"
        "You must incorporate all of them naturally into a single bullet:\n\n"
        "{used_keywords}\n\n"
        "---\n\n"
        "ã€Style Guidelinesã€‘\n"
        "- Begin with a strong action verb\n"
        "- Vary your action verbs across different bullets. Do not start more than one bullet with the same verb (e.g., â€Utilized", â€Implemented", â€Developed", etc.)\n"
        "- Prefer strong and precise action verbs like â€Designed", â€Orchestrated", â€Built", â€Engineered", â€Streamlined", â€Launched", â€Analyzed", etc.\n"
        "- Structure your bullet with an action verb, followed by the method or tools used, and finish with a specific result or business impact\n"
        "- Tone should be confident, concise, and humanâ€”not overly polished or robotic\n"
        "- Avoid buzzwords like "demonstrated" or "proven ability to"\n"
        "- NEVER invent new facts or tasks not in the original bullet\n"
        "- Do NOT use markdown or bullet characters like '-', '*', or '`'\n\n"
        "---\n\n"
        "ã€Outputã€‘\n"
        "Only provide the final rewritten bullet.\n"
        "Do NOT explain anything.\n"
        "Do NOT wrap it in quotes or markdown."
    )

    if results_df.empty or "Rewrite_Status" not in results_df.columns:
        return pd.DataFrame()

    df = results_df[results_df['Rewrite_Status'] == 'Rewrite'].copy()   

    rewritten_rows = []

    for _, row in df.iterrows():
        bullet_id = row.get("bullet_id", "")
        clean_bullet = row.get("cleaned_bullet", "")
        goal = row.get("Goal", "")
        impact = row.get("Impact", "")
        keywords = row.get("rewrite_keywords", [])

        if not isinstance(keywords, list) or not keywords:
            continue

        # Clean keyword string
        keyword_lines = "\n".join(f"- {kw}" for kw in keywords)

        # Generate prompt
        system_prompt = system_prompt_template.format(
            original_bullet=clean_bullet,
            goal=goal,
            impact=impact,
            used_keywords=keyword_lines
        )

        response = gpt_call(system_prompt, model=model, temperature=temperature)
        rewritten = response["content"].strip()

        # Remove meaningless responses
        skip_phrases = [
            "no changes needed", "original bullet", "recommend keeping",
            "already strong", "already optimal", "already clear",
            "already effective", "return it unchanged"
        ]
        if (
            any(phrase in rewritten.lower() for phrase in skip_phrases)
            or clean_bullet.strip() in rewritten
            or rewritten.strip() in ['""', "''"]
        ):
            rewritten = ""

        # âœ… Apply post-processing
        rewritten = clean_output(rewritten)

        rewritten_rows.append({
            "bullet": clean_bullet,
            "bullet_id": bullet_id,
            "rewritten_bullet": rewritten,
            "token_total": response.get("total_tokens", 0),
            "cost_usd": response.get("cost_usd", 0.0),
            "Used_Keywords": keywords
        })

    return pd.DataFrame(rewritten_rows)



### 8) == Score Calculation / Top-K Selection by Company === ###

def compute_responsibility_scores(responsibility_struct: list[dict], bullet_df: pd.DataFrame) -> pd.DataFrame:
    """
    Calculate semantic similarity with bullets based on structured responsibilities.
    """

    # 1ï¸âƒ£ Recombine responsibility items â†’ semantic sentences
    responsibility_sentences = []
    for item in responsibility_struct:
        skills = ", ".join(item.get("skills", []))
        goals  = ", ".join(item.get("goals", []))
        if skills or goals:
            responsibility_sentences.append(f"{skills} â†’ {goals}")

    print("ðŸ“Œ Responsibility Semantic Sentences:")
    for r in responsibility_sentences:
        print(f" - {r}")

    if not responsibility_sentences:
        return pd.DataFrame(columns=["bullet_id", "responsibility_score"])

    # 2ï¸âƒ£ Create embedding dictionary
    resp_embed_map = {r: get_embed(r) for r in responsibility_sentences}

    results = []
    for _, row in bullet_df.iterrows():
        bullet_text = str(row.get("final_bullet", "")).strip()
        if not bullet_text:
            continue
        v_bullet = get_embed(bullet_text)
        sims = [cosine(v_bullet, v_resp) for v_resp in resp_embed_map.values()]
        score = round(max(sims), 4) if sims else 0.0
        results.append({"bullet_id": row["bullet_id"], "responsibility_score": score})

    return pd.DataFrame(results)


# â”€â”€â”€ Select Top-K bullets per company (JD keyword cover ratio + fast_score) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def select_top_bullets_by_company(
    resume_df: pd.DataFrame,
    k_default: int = 3,
    k_min_recent: int = 4,
    k_max_recent: int = 5,
    n_recent_company: int = 2
) -> tuple[set[str], pd.DataFrame]:
    """
    Group bullets by company,
    Select Top-K bullets based on End descending + Impact_Rank ascending + company_score.

    Returns
    -------
    - Selected bullet_text set (set)
    - Selected row full info DataFrame (including company_score)
    """
    print("ðŸ“¥ [select_top_bullets_by_company] Start")

    try:
        # Ensure required columns
        if "Organization" not in resume_df.columns:
            resume_df["Organization"] = "Unknown Org"

        if "company_score" not in resume_df.columns:
            raise ValueError("company_score column is missing. Make sure it is precomputed.")

        # ðŸ”¹ Convert End â†’ datetime
        resume_df["End_dt"] = pd.to_datetime(resume_df["End"], errors="coerce")

        # Extract recent companies
        recent_orgs = (
            resume_df.sort_values("End_dt", ascending=False)["Organization"]
                     .dropna().unique()[:n_recent_company]
        )

        keep_rows: list[pd.Series] = []

        for org, grp in resume_df.groupby("Organization"):
            is_recent = org in recent_orgs
            k_base = k_min_recent if is_recent else k_default

            # ðŸ” Sorting criteria: Recent bullet â†’ Low Impact_Rank â†’ High company_score
            grp_sorted = grp.sort_values(
                by=["End_dt", "Impact_Rank", "company_score"],
                ascending=[False, True, False]
            )

            top_rows = grp_sorted.head(k_base).to_dict(orient="records")

            # If recent company, supplement lacking bullets
            if is_recent and len(top_rows) < k_max_recent:
                additional_rows = grp_sorted.iloc[k_base:k_max_recent].to_dict(orient="records")
                top_rows.extend(additional_rows)

            keep_rows.extend(top_rows)

        df_out = pd.DataFrame(keep_rows)

    except Exception as e:
        print("âŒ Exception occurred:", e)
        import traceback
        traceback.print_exc()
        return set(), pd.DataFrame()

    selected_set = set(df_out["bullet_text"]) if not df_out.empty and "bullet_text" in df_out.columns else set()
    return selected_set, df_out



# Match based on Responsibilities â†” Resume Bullet structure

def select_relevant_resume_bullets_semantic(responsibility_struct, resume_df, top_k_fast=5, top_n_final=2):
    if not responsibility_struct:
        return ""

    top_responsibility = f"{', '.join(responsibility_struct[0]['skills'])} â†’ {', '.join(responsibility_struct[0]['goals'])}"

    resume_df = resume_df.copy()
    resume_df["End"] = resume_df["End"].replace("Present", None)
    resume_df["End"] = pd.to_datetime(resume_df["End"], format="%Y-%m", errors="coerce")
    today = pd.Timestamp.today()
    current_jobs = resume_df[(resume_df["End"].isna()) | (resume_df["End"] >= today)].copy()
    if current_jobs.empty:
        latest_end = resume_df["End"].max()
        current_jobs = resume_df[resume_df["End"] == latest_end].copy()

    if current_jobs.empty:
        return ""

    current_jobs["fast_score"] = current_jobs.apply(
        lambda row: compute_fast_score({
            "keyword": "",
            "meaning": top_responsibility,
            "bullet_text": row["final_bullet"],
            "Tool": row.get("Tool", ""),
            "Skill": "",
            "Goal": "",
            "Impact": ""
        }), axis=1
    )

    top_candidates = current_jobs.sort_values(
        ["fast_score", "Impact_Rank"],
        ascending=[False, True]
    ).head(top_k_fast)

    prompts = [
        {
            "role": "user",
            "content": f"""You're a resume reviewer. Judge the semantic alignment between the following resume bullet and a job responsibility.

Resume Bullet:
"{row['final_bullet']}"

Responsibility:
"{top_responsibility}"

Respond with ONLY one word: "match" or "no match"."""
        }
        for _, row in top_candidates.iterrows()
    ]

    matches = []
    for i, prompt in enumerate(prompts):
        result = gpt_call(prompt=prompt["content"], model=MODEL_FAST, temperature=0)
        label = result["content"].strip().lower()
        if label == "match":
            matches.append(top_candidates.iloc[i]["final_bullet"])

    return "\n".join(matches[:top_n_final])


### 9) == Profile & Summary Processing === ###

# Process Experience JSON and convert to summary text
def add_duration_to_profile(profile_list):
    enriched = []
    for item in profile_list:
        try:
            start_dt = datetime.strptime(item["start"], "%Y.%m.%d")
            end_dt   = datetime.strptime(item["end"], "%Y.%m.%d")
            item["start_dt"] = start_dt
            item["end_dt"]   = end_dt

            total_months = (end_dt.year - start_dt.year) * 12 + (end_dt.month - start_dt.month)
            years, months = divmod(total_months, 12)
            duration = []
            if years:
                duration.append(f"{years} yr{'s' if years > 1 else ''}")
            if months:
                duration.append(f"{months} mo{'s' if months > 1 else ''}")
            item["duration"] = " ".join(duration)
        except Exception:
            item["duration"] = "N/A"
        enriched.append(item)
    return enriched



def format_profile_summary(profile_with_duration):
    lines = []
    for item in profile_with_duration:
        try:
            start_dt = item.get("start_dt")
            end_dt = item.get("end_dt")
            is_current = not end_dt or str(item.get("end", "")).lower() in ["present", ""]

            if isinstance(start_dt, datetime):
                start_str = start_dt.strftime("%b %Y")
            else: 
                start_str = str(item.get("start", "N/A"))

            if is_current:
                end_str = "Present"
            elif isinstance(end_dt, datetime):
                end_str = end_dt.strftime("%b %Y")
            else:
                end_str = str(item.get("end", "N/A"))

            current_flag = " (Current)" if is_current else ""
            duration = item.get("duration", "N/A")

            lines.append(
                f"- {item.get('company', 'Unknown')} | {item.get('position', 'Unknown')} | {start_str} â€“ {end_str}{current_flag} ({duration})"
            )

        except Exception as e:
            # fallback: output minimum info
            lines.append(f"- {item.get('company', 'Unknown')} | {item.get('position', 'Unknown')} | {item.get('start', '')} â€“ {item.get('end', '')}")

    return "\n".join(lines)


def extract_keyword_usage_stats(results, soft, tool, hard, knw, ind, edu, exp):
    original_categories = {
        "technologies and tools": tool,
        "hard skills": hard,
        "knowledge": knw,
        "soft skills": soft,
        "industry": ind,
        "education": edu,
        "experience": exp
    }
    all_keywords = set(tool + hard + knw + soft + ind + edu + exp)

    used_keywords_actual = set()
    for row in results:
        used_keywords_actual.update(row.get("Used_Keywords", []))

    unused_soft_skills = [s for s in soft if s not in used_keywords_actual]
    return original_categories, all_keywords, used_keywords_actual, unused_soft_skills

def rewrite_bullet_with_general_keyword(general_keyword: str, bullet_df: pd.DataFrame, model: str = MODEL_FAST) -> dict:
    """
    Rewrite to naturally integrate semantics-based general keyword (general_tool_keyword) into an existing bullet.
    Only rewrite the most semantically similar bullet.
    """
    

    # âœ… Keyword Embedding
    keyword_embed = get_embed(general_keyword)

    # âœ… Search for most similar bullet
    best_bullet = None
    max_sim = -1
    for _, row in bullet_df.iterrows():
        bullet = row.get("final_bullet") or row.get("bullet")
        if not bullet:
            continue
        bullet_embed = get_embed(bullet)
        sim = cosine(keyword_embed, bullet_embed)
        if sim > max_sim:
            best_bullet = bullet
            max_sim = sim

    if not best_bullet:
        print(f"âŒ Could not find a bullet similar to '{general_keyword}'.")
        return {}

    # âœ… Construct GPT Prompt
    system_prompt = """
    You are a professional resume writer.
    Given a resume bullet and a general keyword, rewrite the bullet to naturally incorporate the keyword.
    The keyword must appear exactly as written and should flow naturally in the sentence.
    Respond ONLY with the final bullet. No quotes, markdown, or explanations.
    """

    user_prompt = f"""
    Keyword: {general_keyword}
    Original Bullet: {best_bullet}
    """

    response = gpt_call(
        prompt=[
            {"role": "system", "content": system_prompt.strip()},
            {"role": "user", "content": user_prompt.strip()}
        ],
        model=model,
        temperature=0.3
    )

    rewritten = response["content"].strip()

    return {
        "keyword": general_keyword,
        "original_bullet": best_bullet,
        "rewritten_bullet": rewritten,
        "similarity": round(max_sim, 4)
    }



def apply_semantic_rewrites_to_not_used_tech_keywords(
    results: list[dict],
    merged: pd.DataFrame,
    model: str = MODEL_FAST
) -> set[str]:
    """
    Semantically rewrite by inserting 'not used' technical keywords into resume bullets.
    
    Args:
        results: List from run_keyword_labeling_loop()
        merged: Merged result of bullet_table + rewrite with final_bullet
        model: GPT model name to use (default: MODEL_SLOW â†’ gpt-4-turbo)

    Returns:
        Set of keywords actually added (set[str])
    """
    from tqdm import tqdm

    # 1. Collect only 'not used' tech keywords
    tech_keywords_not_used = set()
    for row in results:
        for kw in row.get("Not_Used_Keywords", []):
            category = row.get("keyword_results", {}).get(kw, {}).get("Category", "")
            if category.lower() == "technologies and tools":
                tech_keywords_not_used.add(kw)

    print(f"ðŸ” Semantics-based review target tech keywords count: {len(tech_keywords_not_used)}")

    # 2. Apply rewrite based on semantic similarity
    used_keywords = set()
    for kw in tqdm(tech_keywords_not_used, desc="ðŸ” GPT Rewriting in progress"):
        result = rewrite_bullet_with_general_keyword(kw, merged, model=model)
        rewritten = result.get("rewritten_bullet")
        original = result.get("original_bullet")

        if rewritten and original:
            match_idx = merged[merged["final_bullet"] == original].index
            if not match_idx.empty:
                idx = match_idx[0]
                current_keywords = merged.at[idx, "Used_Keywords"]
                merged.at[idx, "Used_Keywords"] = sorted(set(current_keywords + [kw]))
                merged.at[idx, "keyword_score"] += 2
                merged.at[idx, "final_bullet"] = rewritten
                used_keywords.add(kw)

    print(f"\nðŸ§  Semantically rewritten tech keywords count: {len(used_keywords)}")
    print(f"ðŸ§  Keyword list: {sorted(used_keywords)}")

    return used_keywords



def build_industry_summary_text(work_experience: list[dict]) -> str:
    """
    Combine sector + description to generate industry/domain text
    """
    entries = []

    for exp in work_experience:
        sector = exp.get("sector", "").strip()
        description = exp.get("description", "").strip()

        if sector and description:
            entries.append(f"{sector}: {description}")
        elif sector:
            entries.append(sector)
        elif description:
            entries.append(description)

    seen = set()
    unique_entries = []
    for entry in entries:
        if entry not in seen:
            seen.add(entry)
            unique_entries.append(entry)

    return " / ".join(unique_entries) if unique_entries else "N/A"

def compute_total_experience_years(work_experience: list[dict]) -> float:
    total_months = 0
    for item in work_experience:
        start = item.get("start_dt")
        end = item.get("end_dt")
        if isinstance(start, datetime) and isinstance(end, datetime):
            months = (end.year - start.year) * 12 + (end.month - start.month)
            total_months += max(months, 0)
    return round(total_months / 12, 1)

def format_years_range_text(total_years: float) -> str:
    base = int(total_years)
    return f"over {base} years"

def select_matched_bullets_from_jd_conversation(jd_responsibilities: list[str], resume_df: pd.DataFrame) -> list[dict]:
    import re
    import json

    # âœ… Filter bullets based on recent company
    resume_df = resume_df.copy()
    resume_df["End_dt"] = pd.to_datetime(resume_df["End"], errors="coerce")
    latest_end = resume_df["End_dt"].max()
    recent_orgs = resume_df[resume_df["End_dt"] == latest_end]["Organization"].unique().tolist()
    filtered_df = resume_df[resume_df["Organization"].isin(recent_orgs)]

    # âœ… Number responsibility list + highlight tools
    numbered_goals = []
    for i, r in enumerate(jd_responsibilities):
        goal_text = r.strip()
        if "â†’" in goal_text:
            tools, goal = map(str.strip, goal_text.split("â†’", 1))
            numbered_goals.append(f"{i+1}. {goal} â€” Tools: {tools}")
        else:
            numbered_goals.append(f"{i+1}. {goal_text}")

    formatted_responsibilities = "\n".join(numbered_goals)

    # âœ… Organize bullet list
    formatted_bullets = "\n".join([
        f"- {b}" for b in filtered_df["final_bullet"].dropna().tolist()
    ])

    # === Construct Prompt ===
    system_prompt = """
You are simulating a structured discussion between:
- A senior recruiter with 20 years of experience hiring BI professionals
- A BI team lead with 10 years of experience managing BI developer teams

You are given:
1. A list of job responsibility goals, ranked by importance (top = most critical)
2. A set of resume bullets from a candidate

Your task:
- Select the top 2 most critical job goals (by number, e.g., 1 and 6)
- For each selected goal, find the resume bullet that best demonstrates alignment with that goal

ðŸ’¡ Guidelines:
- Prefer goals that are ranked higher in the list
- Prefer goals that include frequently repeated keywords (e.g., Power BI, Tableau, SQL)
- The bullet must directly support the goal and include relevant skills/tools

Respond only in JSON list format.
Each item must be a dictionary with the keys: goal_number, goal_text, selected_bullet.
Do not include explanation or markdown.
"""

    user_prompt = f"""
ðŸ“Œ Ranked Job Responsibility Goals:
{formatted_responsibilities}

ðŸ“„ Candidate's Recent Resume Bullets:
{formatted_bullets}

ðŸŽ¯ Task:
Choose the top 2 most critical goals from the list above (by number).
For each goal, return:
- goal_number: the number from the list
- goal_text: the full original goal text (include tools)
- selected_bullet: the best matching resume bullet

Respond only in JSON list format.
Each item must be a dictionary with the keys: goal_number, goal_text, selected_bullet.
"""

    # Debug output
    print("\nðŸ›  [GPT SYSTEM PROMPT]")
    print(system_prompt.strip())
    print("\nðŸ›  [GPT USER PROMPT]")
    print(user_prompt.strip())

    # Call GPT
    response = gpt_call(
        prompt=[
            {"role": "system", "content": system_prompt.strip()},
            {"role": "user", "content": user_prompt.strip()}
        ],
        model=MODEL_SLOW,
        temperature=0.3
    )

    # âœ… Parse JSON response
    parsed = safe_parse_list_json(response["content"])

    matched = []
    for item in parsed:
        if "goal_text" in item and "selected_bullet" in item:
            matched.append({
                "goal_number": item.get("goal_number"),
                "goal_text": item["goal_text"].strip(),
                "selected_bullet": item["selected_bullet"].strip()
            })

    return matched




def generate_summary_debuggable(matched_bullets, profile_summary_text, profile_data, responsibility_text, unused_soft_skills: list[str],target_title: str = None):
    print("ðŸ§ª matched_bullets:", matched_bullets)
    # âœ… If target_title is empty â†’ fallback to most recent position title
    if not target_title:
        latest_title = ""
        work_exps = profile_data.get("work_experience", [])
        if work_exps:
            sorted_exp = sorted(
                work_exps,
                key=lambda w: w.get("end", "") or "9999.12.31",  # Most recent if end is empty or Present
                reverse=True
            )
            latest_title = sorted_exp[0].get("position", "").strip()
        target_title = latest_title or "Data Professional"

    # âœ… industry/domain summary text
    industry_text = build_industry_summary_text(profile_data.get("work_experience", []))

    # âœ… Total experience years
    profile_with_duration = profile_data.get("work_experience", [])
    total_years = compute_total_experience_years(profile_with_duration)
    experience_text = format_years_range_text(total_years)

    # âœ… Certifications
    certifications = profile_data.get("certifications", [])
    cert_text = "\n".join([
        f"- {c['certification_name']} ({c['organization']}, issued {c['issued_at']})"
        for c in certifications
    ]) if certifications else "None"

    # âœ… Skills
    skills = profile_data.get("skills", {})
    skills_text = f"Tools: {', '.join(skills.get('tools', []))}\n" \
                  f"Soft Skills: {', '.join(skills.get('soft_skills', []))}\n" \
                  f"Languages: {', '.join(skills.get('languages', []))}"

    # âœ… Auto-generate Soft Skill sentence (GPT call)
    soft_skill_sentence = ""
    if unused_soft_skills:
        soft_skill_prompt = f"""
You are an AI assistant helping optimize resumes for ATS and recruiter readability.

Given the job responsibilities and a list of unused soft skills, generate **short, behavior-based resume sentences** that reflect each soft skill naturally while aligning with the context of the role.

ðŸ§© Job Responsibilities:
{responsibility_text}

ðŸ§  Unused Soft Skills:
{', '.join(unused_soft_skills)}

âœ… Instructions:
- Output one sentence per soft skill
- Use action verbs and resume tone (no pronouns)
- Include the soft skill keyword directly in the sentence if possible (for ATS optimization)
- Make sure each sentence is relevant to a BI/data/analytics context
- Format your output as a JSON object like:
{{ "Documentation": "...", "Teamwork": "...", ... }}
â—IMPORTANT:
- Enclose all keys in **double quotes**
- Output must be valid JSON â€” no markdown, no explanation

"""

        soft_skill_response = gpt_call(prompt=soft_skill_prompt, model=MODEL_FAST, temperature=0.3)
        
        try:
            raw = soft_skill_response["content"]
            safe = fix_json_keys(raw)
            soft_skill_dict = json.loads(safe)
            soft_skill_sentence = " ".join(soft_skill_dict.values())
        except Exception as e:
            print("âš ï¸ Failed to parse soft skill response:", e)
            soft_skill_sentence = ""

    # âœ… Construct Summary Prompt
    prompt = f"""
You are a professional resume writer and ATS optimization expert.

Your task is to write a 4â€“5 line professional summary paragraph (not bullet points) that appears at the top of a resume. 
This summary should position the candidate as a strong fit for the BI Developer role, based on the job responsibilities and matched resume bullets.

âœ… Use the following structure:
1. Begin with the candidate's current role title and {experience_text} of experience across relevant industries: {industry_text}
2. Highlight tools, platforms, or domains the candidate has worked with, especially those relevant to BI, data, and analytics.
3. Emphasize 1â€“2 real achievements drawn directly from the matched resume bullets that align with business goals or technical needs in the job responsibilities.
4. Just before mentioning languages or certifications, insert the following sentence if provided:  
"{soft_skill_sentence.strip()}"

ðŸ§¾ Candidate Profile Summary:
{profile_summary_text}

ðŸ“Œ Job Responsibilities (used to infer goals and expectations):
{responsibility_text}

ðŸŽ¯ Matched Resume Bullets:
{matched_bullets}

ðŸ› ï¸ Skills:
{skills_text}

ðŸŽ“ Certifications:
{cert_text}

ðŸ›‘ Rules:
- Do NOT use personal pronouns (I, my, etc).
- Do NOT refer to the candidate as "the candidate" or "they".
- Do NOT fabricate or generalize â€” only use what's provided.
- Avoid vague phrases like "various industries" or "many tools" â€” be specific and concrete.

Now write the summary paragraph.
"""

    # Call GPT (Generate final summary)
    response = gpt_call(
        prompt=prompt,
        model=MODEL_SLOW,
        temperature=0.2
    )
    return response["content"]


def extract_used_keywords_by_category(
    original_category_keywords: dict,
    used_keywords_set: set
) -> dict:
    """
    Takes JD original category keyword list and used keyword set,
    Returns tools_used / soft_skills_used lists in their original order.

    Returns:
        {
            "tools_used": [...],
            "soft_skills_used": [...]
        }
    """
    tools_ordered = original_category_keywords.get("technologies and tools", [])
    soft_skills_ordered = original_category_keywords.get("soft skills", [])

    tools_used = [kw for kw in tools_ordered if kw in used_keywords_set]
    soft_used = [kw for kw in soft_skills_ordered if kw in used_keywords_set]

    return {
        "tools_used": tools_used,
        "soft_skills_used": soft_used
    }

def save_final_resume_json(
    profile_path: str,
    bullet_table_path: str,
    summary_path: str,
    output_json_path: str
) -> None:
    """
    Creates final_resume_data.json based on final results.
    - Based on profile.json, bullet_table.csv, bullet_summary.csv
    - Converts to JSON structure including experience, education, certifications, summary, etc.

    Args:
        profile_path: profile.json path
        bullet_table_path: bullet_table.csv path
        summary_path: bullet_summary.csv path
        output_json_path: path to save final JSON
    """
    import pandas as pd
    import json
    from datetime import datetime

    # â”€â”€â”€ 1) Load Profile â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with open(profile_path, 'r', encoding='utf-8') as f:
        profile = json.load(f)

    # â”€â”€â”€ 2) Load Bullet Table â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    bt = pd.read_csv(bullet_table_path, encoding='utf-8-sig')

    # â”€â”€â”€ 3) Construct Experience â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    experiences = []
    default_location = profile.get('contact_info', {}).get('location', "")

    for org_name, group in bt.groupby('Organization'):
        grp = group.copy()
        grp['End_dt'] = pd.to_datetime(grp['End'], format='%Y.%m.%d', errors='coerce')
        grp_sorted = grp.sort_values(by=['End_dt', 'Impact_Rank'], ascending=[False, True]).reset_index(drop=True)

        first = grp_sorted.iloc[0]
        sector   = first.get('Sector', "")
        location = first.get('Location', default_location)
        position = first.get('Position', "").strip()
        job_title = first.get('Job_title', "").strip()
        duration  = first.get('Duration', "")

        def to_yyyy_mm(date_str):
            try:
                parts = date_str.split('.')
                return f"{parts[0]}-{parts[1]}"
            except:
                return date_str

        start = to_yyyy_mm(first.get('Start', ""))
        end   = to_yyyy_mm(first.get('End', ""))

        bullets = grp_sorted['final_bullet'].astype(str).tolist()

        experiences.append({
            "company":  org_name,
            "sector":   sector,
            "location": location,
            "job_title": job_title,
            "position": position,
            "start":    start,
            "end":      end,
            "duration": duration,
            "bullets":  bullets
        })

    def to_dt(e):
        try:
            raw = e["end"]
            if not raw or str(raw).lower() == "present":
                return datetime.max
            return datetime.strptime(str(raw), "%Y-%m-%d")  
        except:
            return datetime.min

    experiences = sorted(experiences, key=to_dt, reverse=True)

    # â”€â”€â”€ 4) Load Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    bs = pd.read_csv(summary_path, encoding='utf-8-sig')
    summary_text = ""
    if 'summary' in bs.columns and not bs.empty:
        summary_text = bs.loc[0, 'summary']

    # â”€â”€â”€ 5) Convert Certifications â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    certs = []
    for cert in profile.get('certifications', []):
        name = cert.get('certification_name', "")
        orgn = cert.get('organization', "")
        issued = cert.get('issued_at', "")
        if name and orgn and issued:
            certs.append(f"{name}, {orgn} | {issued}")

    # â”€â”€â”€ 6) Convert Education â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    educations = []
    for ed in profile.get('education', []):
        inst  = ed.get('institution', "")
        loc   = ed.get('location', "")
        deg   = ed.get('degree', "")
        field = ed.get('field_of_study', "")
        start = ed.get('start', "")
        end   = ed.get('end', "")
        year  = end[:4] if end else ""

        educations.append(f"{inst}, {loc} | {deg} degree in {field} | {year}")

    # â”€â”€â”€ 7) Assemble final JSON structure â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    final_json = {
        "name":  profile.get('contact_info', {}).get('name', ""),
        "title": profile.get('title', "Data Analyst"),
        "contact": {
            "email":    profile.get('contact_info', {}).get('email', ""),
            "phone":    profile.get('contact_info', {}).get('phone', ""),
            "linkedin": profile.get('contact_info', {}).get('linkedin', ""),
            "website":  profile.get('contact_info', {}).get('website', "")
        },
        "summary":        summary_text,
        "experience":     experiences,
        "certifications": certs,
        "skills":         profile.get('skills', {}),
        "education":      educations
    }

    # â”€â”€â”€ 8) Save â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with open(output_json_path, 'w', encoding='utf-8') as fout:
        json.dump(final_json, fout, ensure_ascii=False, indent=2, default=str)

    print(f"âœ… Final JSON saved successfully â†’ {output_json_path}")



### 10) == GPT Usage Log === ###

def summarize_costs():
    df = pd.DataFrame(usage_records)
    if "cost_usd" in df.columns:
        total_cost = df["cost_usd"].sum()
        print(f"ðŸ’° Total GPT usage cost: ${total_cost:.4f}")
        summary = df.groupby("caller")["cost_usd"].sum().reset_index()
        print("ðŸ’° GPT cost summary by Caller:")
        print(summary.to_string(index=False))
    else:
        print("âš ï¸ No GPT usage records found or 'cost_usd' column missing.")


# === Main ===
async def main():
    start = time.time()
    total_cost = 0.0

    alias_map_path = "/Users/julee/Bullets/resume-ai-service/data/keyword_alias_map.csv"
    alias_map, alias_to_key = load_alias_map(alias_map_path)
    PROFILE_PATH = "/Users/julee/Bullets/resume-ai-service/data/profile.json"
    RESUME_CSV_PATH = "/Users/julee/Bullets/resume-ai-service/data/Resume_Table.csv"
    BULLET_TABLE_OUT = '/Users/julee/Bullets/resume-ai-service/data/Bullet_table.csv'
    SUMMARY_PATH = "/Users/julee/Bullets/resume-ai-service/data/bullet_summary.csv"
    CSV_OUT = "/Users/julee/Bullets/resume-ai-service/data/bullet_keyword_gpt_results.csv"
    SELECTED_BULLETS_OUT = "/Users/julee/Bullets/resume-ai-service/data/selected_top_bullets_by_company.csv"


    with open(PROFILE_PATH, "r", encoding="utf-8") as f:
        profile_data  = json.load(f)

    profile_tools = set(profile_data["skills"].get("tools", []))

    # JD Collection & Keyword Extraction
    jd_info = await get_jd_info_interactive()

    # Used later
    jd_text = jd_info["jd_text"]
    job_title = jd_info["job_title"]
    company = jd_info["company"]
    location = jd_info["location"]
    post_url = jd_info["post_url"]

    job_title, tool, hard, knw, soft, ind, edu, exp, category_map, jd_cost = extract_keywords_from_jd_text(jd_text, job_title,alias_map=alias_map)
    total_cost += jd_cost
    keywords = tool + hard + knw + soft + ind  # Exclude EDU
    jd_kw_set = set(keywords)
    
    print("ðŸ§¾ Final keywords before filtering:", keywords)
    
    with open("/Users/julee/Bullets/resume-ai-service/data/jd_info.json", "w", encoding="utf-8") as f:
        json.dump(jd_info, f, ensure_ascii=False, indent=2)

    # Extract JD Responsibilities (for summary)
    responsibility_struct = await extract_responsibilities(jd_text)
    responsibility_sentences = [
        f"{', '.join(item['skills'])} â†’ {', '.join(item['goals'])}"
        for item in responsibility_struct if item.get("skills") or item.get("goals")
    ]

    # Resume â†’ JD Matching (fast_score + GPT analysis)
    filtered_df, match_cost = process_resume_matching(
    jd_text=jd_text,
    keywords=keywords,
    category_map=category_map,
    resume_csv_path=RESUME_CSV_PATH)

    total_cost += match_cost
    print("ðŸ“‹ Remaining bullets after fast_score/jaccard filter:", len(filtered_df))


    # 7. GPT-based keyword usage determination
    results = run_keyword_labeling_loop(
        df=filtered_df,               # df passed label=1
        profile_tools=profile_tools,
        jd_kw_set=jd_kw_set,
        alias_map=alias_map
    )

    results_df = pd.DataFrame(results)
    results_df = add_clean_and_id(results_df)
    results_df["End_dt"] = pd.to_datetime(results_df["End"], errors="coerce")
    results_df = results_df.sort_values(by=["End_dt", "Impact_Rank"], ascending=[False, True]).reset_index(drop=True)
    results_df.to_csv(CSV_OUT, index=False, encoding="utf-8-sig")
    print(f"âœ… Final CSV saved successfully â†’ {CSV_OUT}")

    # Step 4. Generate Bullet table + calculate score + sort included
    bullet_table = prepare_bullet_table(results_df)
    rewrites_df = execute_rewrites(results_df)

    # Merge rewriting and determine final_bullet
    # ðŸ”¹ 1. Merge bullet_table + rewrites (keyword score, used_kw)
    merged = bullet_table.merge(
    results_df[["cleaned_bullet", "bullet_id", "Used_Keywords", "keyword_score"]],
    left_on=["bullet", "bullet_id"],
    right_on=["cleaned_bullet", "bullet_id"],
    how="left"
    )

    merged.drop(columns=["cleaned_bullet"], inplace=True)

    # 2ï¸âƒ£ Merge bullet_table + rewrite results
    merged = merged.merge(
        rewrites_df[["bullet", "bullet_id", "rewritten_bullet", "token_total", "cost_usd"]],
        on=["bullet", "bullet_id"],
        how="left"
    )

    # ðŸ”¹ 2. Generate final_bullet (prioritize existing rewriting)
    merged["final_bullet"] = merged.apply(
        lambda row: row["rewritten_bullet"] if pd.notna(row["rewritten_bullet"]) else row["bullet"],
        axis=1
    )

    # âœ… Run pre-embedding
    prewarm_embeddings(
        bullets=merged["final_bullet"].tolist(),
        responsibilities=responsibility_sentences,
        keyword_meanings=[
            info["Meaning"]
            for row in results
            for info in row.get("keyword_results", {}).values()
            if "Meaning" in info
        ]
    )

    semantic_keywords_used = apply_semantic_rewrites_to_not_used_tech_keywords(
        results=results,
        merged=merged,
        model=MODEL_FAST
    )
    # âœ… Check semantically rewritten keywords
    if semantic_keywords_used:
        print("\nðŸ§© Semantic rewriting result summary")
        print(f"- Number of used keywords: {len(semantic_keywords_used)}")
        print(f"- List of used keywords: {sorted(semantic_keywords_used)}")
    else:
        print("\nðŸ§© No keywords were semantically rewritten.")

    # ðŸ”¹ 3. Score calculation
    merged = compute_company_score(merged, jd_keywords=jd_kw_set)

    # ðŸ”¹ 4. Responsibility score
    responsibility_scores_df = compute_responsibility_scores(responsibility_struct, merged)
    merged = merged.merge(responsibility_scores_df, on="bullet_id", how="left")
    merged["responsibility_score"] = merged["responsibility_score"].fillna(0.0)
    
    score_cols = ["cover_ratio", "company_score", "responsibility_score"]
    for col in score_cols:
        if col in merged.columns:
            merged[col] = pd.to_numeric(merged[col], errors="coerce")
            merged[col] = merged[col].apply(lambda x: f"{x:.2f}" if pd.notnull(x) else "")

    merged = merged.sort_values(by=["End_dt", "Impact_Rank"], ascending=[False, True])
    merged.to_csv(BULLET_TABLE_OUT, index=False, encoding='utf-8-sig', quoting=csv.QUOTE_MINIMAL)

    selected_bullets, selected_df_out = select_top_bullets_by_company(
    resume_df        = merged,
    k_default        = 3,
    k_min_recent     = 4,
    k_max_recent     = 5,
    n_recent_company = 2
    )

    for col in score_cols:
        selected_df_out[col] = pd.to_numeric(selected_df_out[col], errors="coerce")
    selected_df_out = selected_df_out.sort_values(["End_dt", "Impact_Rank"], ascending=[False, True])
    selected_df_out.to_csv(SELECTED_BULLETS_OUT, index=False, encoding="utf-8-sig")
    print("ðŸ§ª Top-K bullet extraction complete")


    # Step 7. Generate Summary
    # === Generate Summary ===
    matched_bullets = select_matched_bullets_from_jd_conversation(
        jd_responsibilities=responsibility_sentences,
        resume_df=selected_df_out
    )
    profile_enriched = add_duration_to_profile(profile_data["work_experience"])
    profile_summary_text = format_profile_summary(profile_enriched)
    responsibility_text_formatted = "\n".join([f"- {r}" for r in responsibility_sentences])

    original_categories, all_keywords, used_keywords_actual, unused_soft_skills = extract_keyword_usage_stats(
        results, soft, tool, hard, knw, ind, edu, exp
    )

    summary = generate_summary_debuggable(
        matched_bullets,
        profile_summary_text,
        profile_data,
        responsibility_text_formatted,
        unused_soft_skills,
        target_title=job_title
    )
    pd.DataFrame([{"summary": summary}]).to_csv(SUMMARY_PATH, index=False, encoding="utf-8-sig")
    print("Extracted summary :")
    print(summary)

    # === Calculate Final Score ===
    # âœ… Full JD keyword list

    all_keywords = set(tool + hard + knw + soft + ind + edu + exp)

    # Used keywords based on bullets
    used_keywords_actual = set()
    for row in results:
        used_keywords_actual.update(row.get("Used_Keywords", []))

    # Used keywords based on profile
    profile_data_no_datetime = remove_datetime(profile_data)
    profile_used = extract_profile_used_keywords(
        profile_data=profile_data_no_datetime,
        all_keywords=all_keywords,
        alias_map=alias_map,
        alias_to_key=alias_to_key,
        force_soft_skills=soft
    )

    # Used keywords based on summary
    summary_used_keywords = {
        kw for kw in all_keywords
        if re.search(rf'\b{re.escape(kw.lower())}\b', summary.lower())
    }

    # âœ… Final integration
    experience_keywords_used = set()
    total_years = compute_total_experience_years(profile_data.get("work_experience", []))
    rounded_years = math.floor(total_years)
    

    for exp_kw in exp:
        try:
            if int(exp_kw) <= rounded_years:
                experience_keywords_used.add(exp_kw)
        except ValueError:
            continue


    # âœ… Integrate final used keywords
    used_keywords_total = (
        used_keywords_actual
        .union(profile_used)
        .union(summary_used_keywords)
        .union(experience_keywords_used)
    )

    used_by_category = extract_used_keywords_by_category(
    original_category_keywords=original_categories,
    used_keywords_set=used_keywords_total)

    # âœ… Score calculation
    keyword_importance = {kw: "important" for kw in all_keywords}
    resume_score = compute_resume_score(
        original_categories=original_categories,
        used_keywords=used_keywords_total,
        work_experience=profile_data.get("work_experience", []),
        keyword_importance=keyword_importance
    )
    print(f"\nðŸ“ My total years of experience: {total_years} years")
    print(f"ðŸ§¾ Keywords meeting experience condition: {sorted(experience_keywords_used)}")

    # === Print used keyword statistics ===
    used_count = len(used_keywords_total)
    total_count = len(all_keywords)
    used_ratio = (used_count / total_count) * 100 if total_count else 0

    print("\nðŸ“Š Keyword Usage Report")
    print(f"- Total extracted keywords: {total_count}")
    print(f"- Actually used keywords: {used_count}")
    print(f"- Usage rate: {used_ratio:.1f}%")
    print(f"- Used keywords:\n  {sorted(used_keywords_total)}")

    # === Print unused keywords by category ===
    unused_by_category = {}
    for cat, kws in original_categories.items():
        missing = [kw for kw in kws if kw not in used_keywords_total]
        if missing:
            unused_by_category[cat] = missing

    print("\nðŸ“‹ Unused keywords (by category):")
    for cat, kws in unused_by_category.items():
        print(f"- {cat} ({len(kws)} count): {kws}")


    # âœ… Save final_profile.json
    with open("/Users/julee/Bullets/resume-ai-service/data/final_profile.json", "w", encoding="utf-8") as fout:
        safe_profile_data = remove_datetime(profile_data)
        # ðŸ” Debugging: Check if JSON is serializable first
        try:
            json.dumps(safe_profile_data)  # â†’ Test if serializable
        except TypeError as e:
            print("âŒ Found non-serializable object in profile_data:")
            import traceback
            traceback.print_exc()
            raise e  # Re-raise exception

        json.dump(safe_profile_data, fout, ensure_ascii=False, indent=2)

    print("âœ… Final profile saved successfully â†’ data/final_profile.json")

    save_final_resume_json(
    profile_path=PROFILE_PATH,
    bullet_table_path=SELECTED_BULLETS_OUT,
    summary_path=SUMMARY_PATH,
    output_json_path="/Users/julee/Bullets/resume-ai-service/templates/final_resume_data.json"
    )

    TEMPLATE_DIR = '/Users/julee/Bullets/resume-ai-service/templates'
    TEMPLATE_FILE = 'resume_template.html'
    DATA_PATH     = '/Users/julee/Bullets/resume-ai-service/templates/final_resume_data.json'
    OUTPUT_PATH   = '/Users/julee/Bullets/resume-ai-service/templates/resume_output.html'

    # Load JSON
    with open(DATA_PATH, encoding='utf-8') as f:
        data = json.load(f)

    # Load and render Jinja2 template
    env = Environment(loader=FileSystemLoader(TEMPLATE_DIR))
    template = env.get_template(TEMPLATE_FILE)
    html_output = template.render(**data)

    # Save HTML file
    with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:
        f.write(html_output)

    print("âœ… resume_output.html file has been created.")

    # === GPT usage cost summary ===
    df_usage = pd.DataFrame(usage_records)
    if "cost_usd" in df_usage.columns:
        total_cost = df_usage["cost_usd"].sum()
        print("â†’ per-call cost sum:", total_cost)
    else:
        print("âš ï¸ No GPT usage records found or 'cost_usd' column missing.")

    df_usage.to_csv("/Users/julee/Bullets/resume-ai-service/data/gpt_usage_log.csv", index=False)

    # ðŸ”š Execution time end
    print("\nðŸ“ˆ Final Resume Matching Score (Post-matching): {:.1f}/100".format(resume_score))
    print(f"â± Total execution time: {time.time() - start:.2f} seconds")
    os.system('say "Done"')


if __name__ == "__main__":
    try:
        asyncio.run(main())   # â† Run only here!
    except Exception as e:
        print("âŒ Error occurred:", e)
        raise
